{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511a410",
   "metadata": {},
   "source": [
    "A function to read the json-like file spotify provides us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520cb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_df(file_path):\n",
    "    records = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # skip empty lines\n",
    "            try:\n",
    "                # Convert the string representation to a dict\n",
    "                record = ast.literal_eval(line)\n",
    "                records.append(record)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line {i} in {file_path}: {e}\")\n",
    "    # Use json_normalize to flatten nested dictionaries\n",
    "    df = pd.json_normalize(records)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd3d43",
   "metadata": {},
   "source": [
    "# Spotify-Deezer matching data, but only the Spotify part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9a296",
   "metadata": {},
   "source": [
    "This is for the data pulled specificaly to pair Deezer and Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270fd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_file_to_df('../../Data/Raw/spotify_deezer_data_1.txt')\n",
    "df.to_csv('../../Data/Raw/spotify_deezer_data_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f90422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/Raw/spotify_deezer_data_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c2d3a",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e012f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        artist_1 artist_2 artist_3 artist_4\n",
      "0                          Márió     None     None     None\n",
      "1  Count Basie And His Orhcestra     None     None     None\n",
      "2                    Gene Ammons     None     None     None\n",
      "3               The Funsong Band     None     None     None\n",
      "4                Various Artists     None     None     None\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['name', 'artists', 'album.name', 'duration_ms', 'popularity', 'id', 'external_ids.isrc', 'album.release_date_precision', 'album.release_date', 'album.total_tracks', 'disc_number', 'available_markets']\n",
    "df_reduced = df[columns_to_keep]\n",
    "df_reduced = df_reduced.drop_duplicates(subset='id', keep='first')\n",
    "# Extract the first few artist names from the 'artists' column\n",
    "df_reduced['artist_1'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[0]['name'] if len(ast.literal_eval(x)) > 0 else None)\n",
    "df_reduced['artist_2'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[1]['name'] if len(ast.literal_eval(x)) > 1 else None)\n",
    "df_reduced['artist_3'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[2]['name'] if len(ast.literal_eval(x)) > 2 else None)\n",
    "df_reduced['artist_4'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[3]['name'] if len(ast.literal_eval(x)) > 3 else None)\n",
    "\n",
    "# Drop the original 'artists' column (not for now, only once I'm fully sure how many artists we want to keep)\n",
    "df_reduced = df_reduced.drop(columns=['artists'])\n",
    "\n",
    "print(df_reduced[['artist_1', 'artist_2', 'artist_3', 'artist_4']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c817629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.to_csv('../../Data/Processed/spotify_deezer_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5f1ba",
   "metadata": {},
   "source": [
    "# The Spotify Only Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbd4c2",
   "metadata": {},
   "source": [
    "Outdated, was there when we were only pulling data from spotify, now also needs to filter the songs we took using isrc from deezer, so DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I really should have shoved them into a single folder, but I can't be bothered to move them now - V\n",
    "# Glob Glob Glob\n",
    "all_files = glob.glob('../../Data/Raw/*.txt')  \n",
    "dataframes = [load_file_to_df(file) for file in all_files if 'unique_songs' not in file]\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "df_all = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(df_all.head())\n",
    "df_all.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bea0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('../../Data/Raw/spotify_data_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09f78e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../../Data/Raw/spotify_data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12560104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum number of items in the 'artists' column\n",
    "max_artists_count = df_reduced['artists'].apply(lambda x: len(ast.literal_eval(x))).max()\n",
    "print(f\"The maximum number of items in the 'artists' column is: {max_artists_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79449b",
   "metadata": {},
   "source": [
    "10 artists for some songs? Do we want all of those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce579eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['name', 'artists', 'album.name', 'duration_ms', 'popularity', 'id', 'external_ids.isrc', 'album.release_date_precision', 'album.release_date', 'album.total_tracks', 'disc_number', 'available_markets']\n",
    "df_reduced = df_all[columns_to_keep]\n",
    "df_reduced = df_reduced.drop_duplicates(subset='id', keep='first')\n",
    "\n",
    "df_reduced['artist_1'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[0]['name'] if len(ast.literal_eval(x)) > 0 else None)\n",
    "df_reduced['artist_2'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[1]['name'] if len(ast.literal_eval(x)) > 1 else None)\n",
    "df_reduced['artist_3'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[2]['name'] if len(ast.literal_eval(x)) > 2 else None)\n",
    "df_reduced['artist_4'] = df_reduced['artists'].apply(lambda x: ast.literal_eval(x)[3]['name'] if len(ast.literal_eval(x)) > 3 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0af24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.to_csv('../../Data/Processed/spotify_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
