{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15919550-e9fc-4681-93f0-a6553b09ddef",
   "metadata": {},
   "source": [
    "# Kworb.net Spotify Most Streamed Artists\n",
    "The code below collects data available on kworb.net that shows us the top 3000 most streamed artists on Spotify, it first collects all the artists' unique URL and puts them in a DF that is then saved to a CSV file (artist_urls.csv). Then the function below iterates through each URL in the CSV and creates a dictionary to contain the data collected from tables. After scraping all the tables for each artist, the data is saved to another .csv (scraped_artist_data.csv).\n",
    "\n",
    "The data contains artists total all time streams, daily streams and total tracks as a lead artist, solo artist and featured artist.\n",
    "\n",
    "We then go back to the main Spotify Most Streamed Artists page to collect all the artists' names to merge with the data we just collected so that we know which rows belong to which artist instead of using the artist's URL as the indentifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f45442-cbe7-41f0-813b-8162fab9b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318f9c3-e9ef-4e84-98f6-88b6ae229cf1",
   "metadata": {},
   "source": [
    "The following code performs the initial web scraping step, where we extract individual Spotify artist page URLs from Kworb's Spotify Most Streamed Artists of All Time page:\n",
    "\n",
    "- A GET request is sent to the main artists page using the requests library\n",
    "- The HTML content of the page is parsed with BeautifulSoup\n",
    "- All \\<a> tags are scanned to find links that match the pattern of individual artist pages (kworb.net/spotify/artist/...html)\n",
    "- Matching URLs are converted into full links by appending the base URL (https://kworb.net) and stored in a list\n",
    "- We print out a few of the links to check if they are correct\n",
    "- The collected artist URLs are saved into a CSV file called artist_urls.csv for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd4d57c-e1d9-40ff-839c-a4303b043df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://kworb.net/spotify/artist/3TVXtAsR1Inumwj472S9r4_songs.html\n",
      "https://kworb.net/spotify/artist/06HL4z0CvFAxyc27GXpf02_songs.html\n",
      "https://kworb.net/spotify/artist/4q3ewBCX7sLwd24euuV69X_songs.html\n",
      "https://kworb.net/spotify/artist/1Xyo4u8uXC1ZmMpatF05PJ_songs.html\n",
      "https://kworb.net/spotify/artist/1uNFoZAHBGtllmzznpCI3s_songs.html\n",
      "CSV saved to: ../../Data/Raw/artist_urls.csv\n"
     ]
    }
   ],
   "source": [
    "# Base URL for the artists page\n",
    "url = 'https://kworb.net/spotify/artists.html'\n",
    "\n",
    "# Send GET request to the base artists page\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Initialise a list for artist URLs\n",
    "artist_links = []\n",
    "\n",
    "# Search for all <a> tags that link to artist pages\n",
    "for a in soup.find_all('a', href=True):\n",
    "    href = a['href']\n",
    "    # Check if the link is an artist page (it will have '/spotify/artist/' in it)\n",
    "    if '/spotify/artist/' in href and href.endswith('.html'):\n",
    "        artist_links.append(\"https://kworb.net\" + href)\n",
    "\n",
    "# Print a few links to check if they're correct\n",
    "for link in artist_links[:5]:\n",
    "    print(link)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(artist_links, columns=['Artist_URL'])\n",
    "\n",
    "# Define the relative path\n",
    "save_path = os.path.join('..', '..', 'Data', 'Raw', 'artist_urls.csv')\n",
    "\n",
    "# Make sure directory exists\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"CSV saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb51ca6a-2aeb-4044-b222-1966f4ebd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Artist_URL\n",
      "0  https://kworb.net/spotify/artist/3TVXtAsR1Inum...\n",
      "1  https://kworb.net/spotify/artist/06HL4z0CvFAxy...\n",
      "2  https://kworb.net/spotify/artist/4q3ewBCX7sLwd...\n",
      "3  https://kworb.net/spotify/artist/1Xyo4u8uXC1Zm...\n",
      "4  https://kworb.net/spotify/artist/1uNFoZAHBGtll...\n",
      "Index(['Artist_URL'], dtype='object')\n",
      "The DataFrame has 3000 rows.\n"
     ]
    }
   ],
   "source": [
    "# Read in the CSV file with artist URLs\n",
    "df = pd.read_csv('../../Data/Raw/artist_urls.csv')\n",
    "\n",
    "# Check if loaded correctly\n",
    "print(df.head())\n",
    "\n",
    "# Check the columns\n",
    "print(df.columns)\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = df.shape[0]\n",
    "print(f\"The DataFrame has {num_rows} rows.\")  # Print the number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f8777-4d71-4bc7-8e92-8307340927d3",
   "metadata": {},
   "source": [
    "The function below scrapes data from an artist's page on Kworb and returns the artist's streams and track totals as  solo artist, lead artist and featured artist.\n",
    "\n",
    "The function starts by sending a GET request to the artist's page URL. If the page loads correctly, it moves on to the next step.\n",
    "Once the page is loaded, BeautifulSoup is used to parse the HTML. \n",
    "\n",
    "The artist's data is stored in a table (\\<tbody>) so the function searches for this specific table in the page. If it doesn't find the table, it prints a message and returns None.\n",
    "\n",
    "The table rows are looped through, and the function takes the relevant information. Each row contains a label (like \"Streams\", \"Daily\", or \"Tracks\"), followed by the data points (total streams or streams as a lead artist etc).\n",
    "\n",
    "All the extracted data is stored in a dictionary so it can be easily accessed later.\n",
    "\n",
    "If there's any issue during the scraping (e.g., the request fails or the data can't be found), an error message is printed and None is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db66bce4-6816-4a51-8291-4dc30b1f8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape artist data from their page\n",
    "def scrape_artist_data(artist_url):\n",
    "    # Send GET request to artist's page\n",
    "    try:\n",
    "        response = requests.get(artist_url)\n",
    "        response.raise_for_status()  # Ensure a successful response\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the tbody containing the streams, daily, and tracks data\n",
    "        tbody = soup.find('tbody')\n",
    "\n",
    "        if not tbody:\n",
    "            print(f\"No tbody found for {artist_url}\")\n",
    "            return None\n",
    "\n",
    "        # Extract rows from the tbody\n",
    "        rows = tbody.find_all('tr')\n",
    "\n",
    "        # Initialize variables to store scraped data\n",
    "        data = {\n",
    "            'artist_url': artist_url,\n",
    "            'total_streams': None,\n",
    "            'streams_as_lead': None,\n",
    "            'solo_streams': None,\n",
    "            'featured_streams': None,\n",
    "            'daily_streams': None,\n",
    "            'tracks_total': None,\n",
    "            'tracks_as_lead': None,\n",
    "            'tracks_solo': None,\n",
    "            'tracks_as_feature': None\n",
    "        }\n",
    "\n",
    "        # Iterate through rows and extract data\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            if len(columns) == 5:\n",
    "                label = columns[0].text.strip()\n",
    "                total = columns[1].text.strip()\n",
    "                as_lead = columns[2].text.strip()\n",
    "                solo = columns[3].text.strip()\n",
    "                as_feature = columns[4].text.strip()\n",
    "\n",
    "                # Assign values based on the label\n",
    "                if label == 'Streams':\n",
    "                    data['total_streams'] = total\n",
    "                    data['streams_as_lead'] = as_lead\n",
    "                    data['solo_streams'] = solo\n",
    "                    data['featured_streams'] = as_feature\n",
    "                elif label == 'Daily':\n",
    "                    data['daily_streams'] = total\n",
    "                elif label == 'Tracks':\n",
    "                    data['tracks_total'] = total\n",
    "                    data['tracks_as_lead'] = as_lead\n",
    "                    data['tracks_solo'] = solo\n",
    "                    data['tracks_as_feature'] = as_feature\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {artist_url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766352f8-6ac7-4359-ad2d-c6eb783ad2ff",
   "metadata": {},
   "source": [
    "This calls the function on each URL in the CSV to scrape each page with a delay to avoid bombarding the servers with requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6936c2c-3bab-4000-be95-dd70ff48088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the scraped data\n",
    "scraped_data = []\n",
    "\n",
    "# Make sure we're referencing the correct column for artist URLs\n",
    "artist_column = 'Artist_URL'\n",
    "\n",
    "# Iterate over each artist URL in the CSV\n",
    "for index, row in df.iterrows():\n",
    "    artist_url = row[artist_column]\n",
    "    \n",
    "    # Scrape data for the current artist\n",
    "    print(f\"Scraping artist URL: {artist_url}\")  # Print the URL being scraped\n",
    "    \n",
    "    # Scrape the data\n",
    "    data = scrape_artist_data(artist_url)\n",
    "    \n",
    "    if data:\n",
    "        scraped_data.append(data)\n",
    "    \n",
    "    # Add a delay\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863ed59-dc19-4f9b-a717-78d894627812",
   "metadata": {},
   "source": [
    "Here we're saving the scraped data to a new CSV file and we check the first few rows to make sure the data was collected correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71247c57-fb78-494d-8b12-aa7ca63fbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Data:\n",
      "                                          artist_url    total_streams  \\\n",
      "0  https://kworb.net/spotify/artist/3TVXtAsR1Inum...  112,592,066,779   \n",
      "1  https://kworb.net/spotify/artist/06HL4z0CvFAxy...  102,222,940,841   \n",
      "2  https://kworb.net/spotify/artist/4q3ewBCX7sLwd...   97,253,221,301   \n",
      "3  https://kworb.net/spotify/artist/1Xyo4u8uXC1Zm...   79,246,015,185   \n",
      "4  https://kworb.net/spotify/artist/1uNFoZAHBGtll...   59,964,949,358   \n",
      "\n",
      "  streams_as_lead    solo_streams featured_streams daily_streams tracks_total  \\\n",
      "0  76,886,517,261  42,430,139,565   35,705,549,518    50,091,662          513   \n",
      "1  98,993,346,012  90,320,824,607    3,229,594,829    49,907,494          593   \n",
      "2  61,472,589,366  34,896,852,568   35,780,631,935    63,464,912          269   \n",
      "3  63,772,467,221  42,714,560,989   15,473,547,964    44,626,887          319   \n",
      "4  36,504,644,580  22,040,079,971   23,460,304,778    22,204,379          289   \n",
      "\n",
      "  tracks_as_lead tracks_solo tracks_as_feature  \n",
      "0            314         197               199  \n",
      "1            579         519                14  \n",
      "2            144          87               125  \n",
      "3            241         169                78  \n",
      "4            206         111                83  \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "scraped_df = pd.DataFrame(scraped_data)\n",
    "\n",
    "# Save the data to a new CSV file\n",
    "scraped_df.to_csv('../../Data/Raw/scraped_artist_data.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the scraped data to check\n",
    "print(scraped_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae948141-17c0-4faa-b735-2ea48350e35a",
   "metadata": {},
   "source": [
    "Now we're going back to the main artist page to collect all the names to merge with the CSV file we just made containing the scraped data, we want to do this so we can replace the URL with the artist's names so it's easier to indentify which row belongs to which artist. Here, we're reading the web page's html to take the first table which contains the artist's data and we only keep the name as the rest of the table's data has been collected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dee0815-09a3-4b1e-8bd6-fb1fc95f5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad Bunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Weeknd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin Bieber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist\n",
       "0          Drake\n",
       "1   Taylor Swift\n",
       "2      Bad Bunny\n",
       "3     The Weeknd\n",
       "4  Justin Bieber"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the HTML from the URL\n",
    "artist_name_data = pd.read_html('https://kworb.net/spotify/artists.html')\n",
    "\n",
    "# Print the number of tables found in the HTML file\n",
    "print(f'Total tables: {len(artist_name_data)}')\n",
    "\n",
    "# Select the first table\n",
    "artist_name_df = artist_name_data[0]\n",
    "\n",
    "# Extract only the 'Artist' column\n",
    "artist_names_df = artist_name_df[['Artist']]\n",
    "\n",
    "# Display the first few rows to check the artists names\n",
    "artist_names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ac248-0acb-48a2-a7f1-2c14a4adcf1a",
   "metadata": {},
   "source": [
    "We then merge the two DFs with the artist names on the left and we drop the column containing the URLs as they're not longer relevant. After checking the data, we then save this new DF as a CSV file (kworb_spotify_top_artists.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f87c55ca-5e1a-4f50-a593-2b3bdc43e6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>artist_url</th>\n",
       "      <th>total_streams</th>\n",
       "      <th>streams_as_lead</th>\n",
       "      <th>solo_streams</th>\n",
       "      <th>featured_streams</th>\n",
       "      <th>daily_streams</th>\n",
       "      <th>tracks_total</th>\n",
       "      <th>tracks_as_lead</th>\n",
       "      <th>tracks_solo</th>\n",
       "      <th>tracks_as_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>https://kworb.net/spotify/artist/3TVXtAsR1Inum...</td>\n",
       "      <td>112,592,066,779</td>\n",
       "      <td>76,886,517,261</td>\n",
       "      <td>42,430,139,565</td>\n",
       "      <td>35,705,549,518</td>\n",
       "      <td>50,091,662</td>\n",
       "      <td>513</td>\n",
       "      <td>314</td>\n",
       "      <td>197</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>https://kworb.net/spotify/artist/06HL4z0CvFAxy...</td>\n",
       "      <td>102,222,940,841</td>\n",
       "      <td>98,993,346,012</td>\n",
       "      <td>90,320,824,607</td>\n",
       "      <td>3,229,594,829</td>\n",
       "      <td>49,907,494</td>\n",
       "      <td>593</td>\n",
       "      <td>579</td>\n",
       "      <td>519</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>https://kworb.net/spotify/artist/4q3ewBCX7sLwd...</td>\n",
       "      <td>97,253,221,301</td>\n",
       "      <td>61,472,589,366</td>\n",
       "      <td>34,896,852,568</td>\n",
       "      <td>35,780,631,935</td>\n",
       "      <td>63,464,912</td>\n",
       "      <td>269</td>\n",
       "      <td>144</td>\n",
       "      <td>87</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>https://kworb.net/spotify/artist/1Xyo4u8uXC1Zm...</td>\n",
       "      <td>79,246,015,185</td>\n",
       "      <td>63,772,467,221</td>\n",
       "      <td>42,714,560,989</td>\n",
       "      <td>15,473,547,964</td>\n",
       "      <td>44,626,887</td>\n",
       "      <td>319</td>\n",
       "      <td>241</td>\n",
       "      <td>169</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>https://kworb.net/spotify/artist/1uNFoZAHBGtll...</td>\n",
       "      <td>59,964,949,358</td>\n",
       "      <td>36,504,644,580</td>\n",
       "      <td>22,040,079,971</td>\n",
       "      <td>23,460,304,778</td>\n",
       "      <td>22,204,379</td>\n",
       "      <td>289</td>\n",
       "      <td>206</td>\n",
       "      <td>111</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Artist                                         artist_url  \\\n",
       "0          Drake  https://kworb.net/spotify/artist/3TVXtAsR1Inum...   \n",
       "1   Taylor Swift  https://kworb.net/spotify/artist/06HL4z0CvFAxy...   \n",
       "2      Bad Bunny  https://kworb.net/spotify/artist/4q3ewBCX7sLwd...   \n",
       "3     The Weeknd  https://kworb.net/spotify/artist/1Xyo4u8uXC1Zm...   \n",
       "4  Justin Bieber  https://kworb.net/spotify/artist/1uNFoZAHBGtll...   \n",
       "\n",
       "     total_streams streams_as_lead    solo_streams featured_streams  \\\n",
       "0  112,592,066,779  76,886,517,261  42,430,139,565   35,705,549,518   \n",
       "1  102,222,940,841  98,993,346,012  90,320,824,607    3,229,594,829   \n",
       "2   97,253,221,301  61,472,589,366  34,896,852,568   35,780,631,935   \n",
       "3   79,246,015,185  63,772,467,221  42,714,560,989   15,473,547,964   \n",
       "4   59,964,949,358  36,504,644,580  22,040,079,971   23,460,304,778   \n",
       "\n",
       "  daily_streams tracks_total tracks_as_lead tracks_solo tracks_as_feature  \n",
       "0    50,091,662          513            314         197               199  \n",
       "1    49,907,494          593            579         519                14  \n",
       "2    63,464,912          269            144          87               125  \n",
       "3    44,626,887          319            241         169                78  \n",
       "4    22,204,379          289            206         111                83  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([artist_names_df, scraped_df], axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a7741c7-2727-45f9-afa0-af6540aacc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(columns=['artist_url'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "382d2eed-828a-4455-9099-a5485359871b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a93f6a8f-74ea-4f83-b27c-f6415c0c8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../../Data/Raw/kworb_spotify_top_artists.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
